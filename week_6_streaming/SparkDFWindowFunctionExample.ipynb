{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1a9149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/31 16:16:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import avg, col, desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0bdfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79cdb4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!echo $PYSPARK_PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3894d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!echo $PYSPARK_DRIVER_PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37bf3d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "732d0086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/anaconda3/envs/dtezoomcamp/bin/python'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f116b9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dtezoomcamp/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!echo $PYSPARK_DRIVER_PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2081be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dtezoomcamp/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!echo $PYSPARK_PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0fb53bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/31 16:20:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Start spark session\n",
    "pyspark_version = pyspark.__version__\n",
    "kafka_jar_package = f\"org.apache.spark:spark-sql-kafka-0-10_2.12:{pyspark_version}\"\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"GeeksForGeeksTestGroupByWindow\") \\\n",
    "    .config(\"spark.jars.packages\", kafka_jar_package) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cb66a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/31 16:33:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/31 16:33:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/31 16:33:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/31 16:33:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/03/31 16:33:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| id|desc_order|\n",
      "+---+----------+\n",
      "|  2|         1|\n",
      "|  1|         2|\n",
      "|  0|         3|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql import Window\n",
    "df = spark.range(3)\n",
    "w = Window.orderBy(df.id.desc())\n",
    "df.withColumn(\"desc_order\", row_number().over(w)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eba89f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+-----+--------------------------+\n",
      "|Name  |Number_of_Trials|Marks|timestamp                 |\n",
      "+------+----------------+-----+--------------------------+\n",
      "|Pulkit|trial_1         |32   |2024-03-31 18:37:51.068331|\n",
      "|Ritika|trial_1         |42   |2024-03-31 18:37:52.068331|\n",
      "|Pulkit|trial_2         |45   |2024-03-31 18:37:53.068331|\n",
      "|Ritika|trial_2         |42   |2024-03-31 18:37:54.068331|\n",
      "|Ritika|trial_3         |75   |2024-03-31 18:37:55.068331|\n",
      "|Pulkit|trial_3         |55   |2024-03-31 18:37:56.068331|\n",
      "|Ritika|trial_4         |75   |2024-03-31 18:37:57.068331|\n",
      "|Pulkit|trial_4         |32   |2024-03-31 18:37:58.068331|\n",
      "+------+----------------+-----+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Define sample data\n",
    "simpleData = [(\"Pulkit\",\"trial_1\",32, '2024-03-31 18:37:51.068331'),\n",
    "    (\"Ritika\",\"trial_1\",42, '2024-03-31 18:37:52.068331'),\n",
    "    (\"Pulkit\",\"trial_2\",45, '2024-03-31 18:37:53.068331'),\n",
    "    (\"Ritika\",\"trial_2\",42, '2024-03-31 18:37:54.068331'),\n",
    "    (\"Ritika\",\"trial_3\",75, '2024-03-31 18:37:55.068331'),\n",
    "    (\"Pulkit\",\"trial_3\",55, '2024-03-31 18:37:56.068331'),\n",
    "    (\"Ritika\",\"trial_4\",75, '2024-03-31 18:37:57.068331'),\n",
    "    (\"Pulkit\",\"trial_4\",32, '2024-03-31 18:37:58.068331')\n",
    "  ]\n",
    " \n",
    "# define the schema\n",
    "schema = [\"Name\",\"Number_of_Trials\",\"Marks\", \"timestamp\"]\n",
    " \n",
    "# create a dataframe\n",
    "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
    "# w = Window.orderBy(df.Name.desc())\n",
    "# df = df.withColumn(\"row_num\", row_number().over(w))\n",
    "# df = df.withColumn('timestamp', (F.current_timestamp() + F.expr('INTERVAL 2 HOURS')).cast('string')) \n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ec5ebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+-----+\n",
      "|window                                    |Marks|count|\n",
      "+------------------------------------------+-----+-----+\n",
      "|{2024-03-31 18:35:00, 2024-03-31 18:40:00}|32   |2    |\n",
      "|{2024-03-31 18:35:00, 2024-03-31 18:40:00}|42   |2    |\n",
      "|{2024-03-31 18:35:00, 2024-03-31 18:40:00}|45   |1    |\n",
      "|{2024-03-31 18:35:00, 2024-03-31 18:40:00}|75   |2    |\n",
      "|{2024-03-31 18:35:00, 2024-03-31 18:40:00}|55   |1    |\n",
      "+------------------------------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "  .groupBy(\n",
    "    F.window(df.timestamp, \"5 minutes\"),\n",
    "    col(\"Marks\"))\\\n",
    "  .count()\\\n",
    "  .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ac0d6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+-----+\n",
      "|window                                    |Marks|count|\n",
      "+------------------------------------------+-----+-----+\n",
      "|{2024-03-31 18:37:50, 2024-03-31 18:37:55}|32   |1    |\n",
      "|{2024-03-31 18:37:50, 2024-03-31 18:37:55}|42   |2    |\n",
      "|{2024-03-31 18:37:50, 2024-03-31 18:37:55}|45   |1    |\n",
      "|{2024-03-31 18:37:55, 2024-03-31 18:38:00}|75   |2    |\n",
      "|{2024-03-31 18:37:55, 2024-03-31 18:38:00}|55   |1    |\n",
      "|{2024-03-31 18:37:55, 2024-03-31 18:38:00}|32   |1    |\n",
      "+------------------------------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "  .groupBy(\n",
    "    F.window(df.timestamp, \"5 seconds\"),\n",
    "    col(\"Marks\"))\\\n",
    "  .count()\\\n",
    "  .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a10e3faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b07e83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
